{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439d3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f85b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\HU\n",
      "[nltk_data]     ZEWEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopWords_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d059614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(x):\n",
    "    if x == 1 or x == 2:\n",
    "        return 0\n",
    "    if x == 3:\n",
    "        return 1\n",
    "    if x == 5 or x == 4:\n",
    "        return 2\n",
    "    \n",
    "# label to name\n",
    "def label2name(x):\n",
    "    if x == 0:\n",
    "        return \"Negative\"\n",
    "    if x == 1:\n",
    "        return \"Neutral\"\n",
    "    if x == 2:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133c770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_df.csv')\n",
    "df[\"label\"] = df[\"Rating\"].apply(lambda x: label_encode(x))\n",
    "df[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b7474",
   "metadata": {},
   "source": [
    "# Preprocess for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58f42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318d3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b261b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    seed_val = 17\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 5 \n",
    "    batch_size = 6\n",
    "    seq_length = 512\n",
    "    lr = 2e-5\n",
    "    eps = 1e-8\n",
    "    pretrained_model = 'bert-base-uncased'\n",
    "    test_size=0.15\n",
    "    random_state=42\n",
    "    add_special_tokens=True \n",
    "    return_attention_mask=True \n",
    "    pad_to_max_length=True \n",
    "    do_lower_case=False\n",
    "    return_tensors='pt'\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff603bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params will be saved after training\n",
    "params = {\"seed_val\": config.seed_val,\n",
    "    \"device\":str(config.device),\n",
    "    \"epochs\":config.epochs, \n",
    "    \"batch_size\":config.batch_size,\n",
    "    \"seq_length\":config.seq_length,\n",
    "    \"lr\":config.lr,\n",
    "    \"eps\":config.eps,\n",
    "    \"pretrained_model\": config.pretrained_model,\n",
    "    \"test_size\":config.test_size,\n",
    "    \"random_state\":config.random_state,\n",
    "    \"add_special_tokens\":config.add_special_tokens,\n",
    "    \"return_attention_mask\":config.return_attention_mask,\n",
    "    \"pad_to_max_length\":config.pad_to_max_length,\n",
    "    \"do_lower_case\":config.do_lower_case,\n",
    "    \"return_tensors\":config.return_tensors,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5867be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed and device\n",
    "import random\n",
    "\n",
    "device = config.device\n",
    "\n",
    "random.seed(config.seed_val)\n",
    "np.random.seed(config.seed_val)\n",
    "torch.manual_seed(config.seed_val)\n",
    "torch.cuda.manual_seed_all(config.seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2bd3d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive park get good deal stay h...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice room 4 experience hotel monaco seattle go...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay go seahawk game awesome ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  label label_name\n",
       "0  nice hotel expensive park get good deal stay h...       4      2   Positive\n",
       "1  ok nothing special charge diamond member hilto...       2      0   Negative\n",
       "2  nice room 4 experience hotel monaco seattle go...       3      1    Neutral\n",
       "3  unique great stay wonderful time hotel monaco ...       5      2   Positive\n",
       "4  great stay great stay go seahawk game awesome ...       5      2   Positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a82f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_, val_df = train_test_split(df, \n",
    "                                    test_size=0.10, \n",
    "                                    random_state=config.random_state, \n",
    "                            stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca638012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>central simple 4 nights bbvery small room airc...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>stay stay flight cancel strand 3 days amaze ho...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>nt want stay pick hotel du candran excellent r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>best deal town reserve internet months advance...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>nice place wife arrive usa 10am offer choice d...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Rating  label  \\\n",
       "8159   central simple 4 nights bbvery small room airc...       3      1   \n",
       "15738  stay stay flight cancel strand 3 days amaze ho...       5      2   \n",
       "9972   nt want stay pick hotel du candran excellent r...       5      2   \n",
       "7265   best deal town reserve internet months advance...       5      2   \n",
       "8747   nice place wife arrive usa 10am offer choice d...       4      2   \n",
       "\n",
       "      label_name  \n",
       "8159     Neutral  \n",
       "15738   Positive  \n",
       "9972    Positive  \n",
       "7265    Positive  \n",
       "8747    Positive  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3170c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df_, \n",
    "                                    test_size=0.10, \n",
    "                                    random_state=42, \n",
    "                            stratify=train_df_.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eaa6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5340d11b572b4680b685bcc9cf2464ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HU ZEWEN\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning:\n",
      "\n",
      "`huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HU ZEWEN\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2d117fe36344f5816221dcebe408a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46e751b184492f891c1f4e710a4dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.pretrained_model, \n",
    "                                          do_lower_case=config.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3265ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\HU ZEWEN\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2354: FutureWarning:\n",
      "\n",
      "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_df.Review.values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_df.Review.values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a6e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_df.label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e90a10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1323f30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3182164573364933afbb5bd6382939b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(config.pretrained_model,\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e75c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=config.batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d42d00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HU ZEWEN\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\optimization.py:391: FutureWarning:\n",
      "\n",
      "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=config.lr, \n",
    "                  eps=config.eps)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*config.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee4ab4",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39a25146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels, label_dict):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d760a53",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4a99318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(config.device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "        \n",
    "    # calculate avareage val loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d7faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85e508020c8404fb1b5258a84c0308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281037d5c6964166b1279e1b43c7d20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(config.device)\n",
    "    \n",
    "for epoch in tqdm(range(1, config.epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "# allows you to see the progress of the training \n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(config.device) for b in batch)\n",
    "        \n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "    \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    \n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}');\n",
    "# save model params and other configs \n",
    "with Path('params.json').open(\"w\") as f:\n",
    "    json.dump(params, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d440f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
