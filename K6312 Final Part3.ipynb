{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb3da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afdad33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tripadvisor_hotel_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3902b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,  \n",
      "\n",
      "Stemming:\n",
      "nice hotel expens park got good deal stay hotel anniversary, arriv late even took advic previous review did valet parking, check quick easy, littl disappoint non-exist view room room clean nice size, bed comfort woke stiff neck high pillows, not soundproof like heard music room night morn loud bang door open close hear peopl talk hallway, mayb just noisi neighbors, aveda bath product nice, did not goldfish stay nice touch taken advantag stay longer, locat great walk distanc shopping, overal nice experi have pay 40 park night,\n",
      "\n",
      "Lemmatization:\n",
      "nice hotel expensive park get good deal stay hotel anniversary, arrive late even take advice previous review do valet parking, check quick easy, little disappoint non-existent view room room clean nice size, bed comfortable wake stiff neck high pillows, not soundproof like hear music room night morning loud bang doors open close hear people talk hallway, maybe just noisy neighbors, aveda bath products nice, do not goldfish stay nice touch take advantage stay longer, location great walk distance shopping, overall nice experience have pay 40 park night,\n"
     ]
    }
   ],
   "source": [
    "print('Original:')\n",
    "print(df['Review'][0])\n",
    "print()\n",
    "\n",
    "sentence = []\n",
    "for word in df['Review'][0].split():\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    sentence.append(stemmer.stem(word))\n",
    "print('Stemming:')\n",
    "print(' '.join(sentence))\n",
    "print()\n",
    "\n",
    "sentence = []\n",
    "for word in df['Review'][0].split():\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence.append(lemmatizer.lemmatize(word, 'v'))\n",
    "print('Lemmatization:')\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc2f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    #remove punctuations and uppercase\n",
    "    clean_text = text.translate(str.maketrans('','',string.punctuation)).lower()\n",
    "    \n",
    "    #remove stopwords\n",
    "    clean_text = [word for word in clean_text.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    #lemmatize the word\n",
    "    sentence = []\n",
    "    for word in clean_text:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        sentence.append(lemmatizer.lemmatize(word, 'v'))\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc909e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44161acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive park get good deal stay h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice room 4 experience hotel monaco seattle go...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay go seahawk game awesome ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive park get good deal stay h...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice room 4 experience hotel monaco seattle go...       3\n",
       "3  unique great stay wonderful time hotel monaco ...       5\n",
       "4  great stay great stay go seahawk game awesome ...       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2ec952",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = [4, 5]\n",
    "neutral = [3]\n",
    "negative = [1, 2]\n",
    "\n",
    "def map_sentiment(rating):\n",
    "    if rating in positive:\n",
    "        return 2\n",
    "    elif rating in neutral:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Sentiment']= df['Rating'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ef4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6e7e1",
   "metadata": {},
   "source": [
    "# Build DL Model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4720124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct words: 65012\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=50000, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# print(tokenizer.word_index)\n",
    "total_word = len(tokenizer.word_index)\n",
    "print('Total distinct words: {}'.format(total_word))\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_seq)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_seq)\n",
    "\n",
    "# One hot encoding the label\n",
    "lb = LabelBinarizer()\n",
    "train_labels = lb.fit_transform(y_train)\n",
    "test_labels = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b607a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
    "pickle.dump(lb, open('label.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d271be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 8)           520096    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32)               3200      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 264       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 523,587\n",
      "Trainable params: 523,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Embedding(total_word, 8),\n",
    "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(8, kernel_regularizer=l2(0.001),\n",
    "                                                          bias_regularizer=l2(0.001), activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(3, activation='softmax')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda246b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "513/513 [==============================] - 263s 507ms/step - loss: 0.9581 - accuracy: 0.6869 - val_loss: 0.7967 - val_accuracy: 0.7243\n",
      "Epoch 2/25\n",
      "513/513 [==============================] - 264s 514ms/step - loss: 0.8273 - accuracy: 0.7347 - val_loss: 0.7248 - val_accuracy: 0.7243\n",
      "Epoch 3/25\n",
      "513/513 [==============================] - 272s 531ms/step - loss: 0.7143 - accuracy: 0.7388 - val_loss: 0.6059 - val_accuracy: 0.7243\n",
      "Epoch 4/25\n",
      "513/513 [==============================] - 267s 520ms/step - loss: 0.6385 - accuracy: 0.7394 - val_loss: 0.5783 - val_accuracy: 0.7243\n",
      "Epoch 5/25\n",
      "513/513 [==============================] - 266s 518ms/step - loss: 0.5877 - accuracy: 0.7394 - val_loss: 0.5563 - val_accuracy: 0.7243\n",
      "Epoch 6/25\n",
      "513/513 [==============================] - 269s 524ms/step - loss: 0.5800 - accuracy: 0.7394 - val_loss: 0.5493 - val_accuracy: 0.7243\n",
      "Epoch 7/25\n",
      "513/513 [==============================] - 269s 525ms/step - loss: 0.5292 - accuracy: 0.7394 - val_loss: 0.5388 - val_accuracy: 0.7243\n",
      "Epoch 8/25\n",
      "513/513 [==============================] - 269s 525ms/step - loss: 0.5096 - accuracy: 0.7394 - val_loss: 0.5562 - val_accuracy: 0.7243\n",
      "Epoch 9/25\n",
      "513/513 [==============================] - 268s 523ms/step - loss: 0.4955 - accuracy: 0.7710 - val_loss: 0.5258 - val_accuracy: 0.8078\n",
      "Epoch 10/25\n",
      "513/513 [==============================] - 269s 523ms/step - loss: 0.4980 - accuracy: 0.7896 - val_loss: 0.5224 - val_accuracy: 0.8234\n",
      "Epoch 11/25\n",
      "513/513 [==============================] - 270s 526ms/step - loss: 0.4471 - accuracy: 0.8200 - val_loss: 0.5169 - val_accuracy: 0.8251\n",
      "Epoch 12/25\n",
      "513/513 [==============================] - 276s 538ms/step - loss: 0.4430 - accuracy: 0.8347 - val_loss: 0.5349 - val_accuracy: 0.8231\n",
      "Epoch 13/25\n",
      "513/513 [==============================] - 274s 535ms/step - loss: 0.4193 - accuracy: 0.8414 - val_loss: 0.5488 - val_accuracy: 0.8324\n",
      "Epoch 14/25\n",
      "513/513 [==============================] - 277s 540ms/step - loss: 0.4171 - accuracy: 0.8424 - val_loss: 0.6299 - val_accuracy: 0.7446\n",
      "Epoch 15/25\n",
      "513/513 [==============================] - 280s 546ms/step - loss: 0.4577 - accuracy: 0.8253 - val_loss: 0.5273 - val_accuracy: 0.8112\n",
      "Epoch 16/25\n",
      "513/513 [==============================] - 277s 541ms/step - loss: 0.4189 - accuracy: 0.8364 - val_loss: 0.5290 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "513/513 [==============================] - 277s 540ms/step - loss: 0.4041 - accuracy: 0.8427 - val_loss: 0.5389 - val_accuracy: 0.8202\n",
      "Epoch 18/25\n",
      "513/513 [==============================] - 279s 545ms/step - loss: 0.3925 - accuracy: 0.8475 - val_loss: 0.5495 - val_accuracy: 0.8197\n",
      "Epoch 19/25\n",
      "513/513 [==============================] - 280s 545ms/step - loss: 0.3822 - accuracy: 0.8523 - val_loss: 0.5641 - val_accuracy: 0.8207\n",
      "Epoch 20/25\n",
      "513/513 [==============================] - 284s 553ms/step - loss: 0.3681 - accuracy: 0.8557 - val_loss: 0.5612 - val_accuracy: 0.8202\n",
      "Epoch 21/25\n",
      "513/513 [==============================] - 287s 559ms/step - loss: 0.3602 - accuracy: 0.8571 - val_loss: 0.5915 - val_accuracy: 0.8197\n",
      "Epoch 22/25\n",
      "513/513 [==============================] - 284s 553ms/step - loss: 0.3493 - accuracy: 0.8592 - val_loss: 0.6061 - val_accuracy: 0.8192\n",
      "Epoch 23/25\n",
      "513/513 [==============================] - 287s 559ms/step - loss: 0.3433 - accuracy: 0.8629 - val_loss: 0.6168 - val_accuracy: 0.8187\n",
      "Epoch 24/25\n",
      "513/513 [==============================] - 287s 559ms/step - loss: 0.3404 - accuracy: 0.8633 - val_loss: 0.6193 - val_accuracy: 0.8200\n",
      "Epoch 25/25\n",
      "513/513 [==============================] - 285s 555ms/step - loss: 0.3325 - accuracy: 0.8662 - val_loss: 0.6227 - val_accuracy: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d166b4fbb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_padded, train_labels, epochs=25, validation_data=(test_padded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2301d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
